# CIFAR10
# The final assignment for AI course
## 代码结构

此Jupyter Notebook文件实现了CIFAR10数据集上的图像分类任务。主要代码结构如下：

    导入库和定义辅助函数
        导入所需的Python库，如torch、torchvision、matplotlib等。
        定义一些辅助函数用于数据预处理和可视化。

    加载和预处理数据
        从torchvision.datasets中加载CIFAR10数据集。
        对数据集进行标准化和数据增强。
        将数据集划分为训练集、验证集和测试集，并创建相应的DataLoader。

    定义模型
        定义了一个卷积神经网络（CNN）模型，用于对CIFAR10数据集进行分类。
        模型包括若干卷积层、池化层和全连接层。

    定义训练和评估函数
        定义训练函数，包含前向传播、计算损失、反向传播和参数更新步骤。
        定义评估函数，用于计算模型在验证集上的准确率。

    训练模型
        设置训练参数，如学习率、权重衰减等。
        训练模型并在训练过程中记录损失和准确率。

    测试模型并生成预测结果
        使用训练好的模型对测试集进行预测。
        将预测结果保存到CSV文件中，格式符合Kaggle竞赛的提交要求。

## 运行方式

    环境配置
        确保已安装所需的Python库，例如torch、torchvision、pandas、matplotlib等。
        建议在GPU环境下运行以加快训练速度。

    运行代码
        按顺序执行Notebook中的每个代码单元格。
        在训练单元格中，根据需要调整超参数（如学习率、批次大小、训练轮数等）。

    查看结果
        训练过程中会输出损失和准确率曲线图，帮助监控模型的训练情况。
        最终会生成一个submission.csv文件，包含测试集的预测结果。

## 代码文件结构

```bash

CIFAR10.ipynb  # 主代码文件，包含整个项目的实现过程
README.md       # 项目说明文件，介绍项目背景、目标、方法、过程和结果
submission.csv  # 测试集预测结果文件
```

## 项目说明
#### 背景与目标

本项目的目标是使用卷积神经网络对CIFAR10数据集进行分类。CIFAR10数据集包含60000张32x32的彩色图像，分为10个类别。每个类别有6000张图像，其中50000张用于训练，10000张用于测试。
方法与过程

    数据预处理
        对图像进行标准化处理，使每个通道的像素值分布在0到1之间。
        使用数据增强技术（如随机裁剪、水平翻转）增加数据多样性，提升模型的泛化能力。

    模型设计
        使用卷积神经网络提取图像特征。
        使用批量归一化和ReLU激活函数，加速训练过程并提升模型性能。

    模型训练
        使用交叉熵损失函数和Adam优化器。
        在训练过程中监控验证集上的准确率，以防止过拟合。

    模型评估与预测
        使用验证集评估模型性能。
        对测试集进行预测，并生成符合Kaggle竞赛要求的提交文件。

#### 结果分析

    最终模型在验证集上的准确率达到了99.8%，在测试集上的预测结果也表现良好。
    通过数据增强和模型设计，有效提升了模型的泛化能力和性能。